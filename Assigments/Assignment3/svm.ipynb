{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('parkinsonsTrainStatML.dt')\n",
    "content = f.read()\n",
    "lines = np.array([np.array(list(map(float, line.split(' ')))) for line in content.split('\\n')[:-1]])\n",
    "ft = open('parkinsonsTestStatML.dt')\n",
    "contentt = ft.read()\n",
    "linest = np.array([np.array(list(map(float, line.split(' ')))) for line in contentt.split('\\n')[:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale data to zero mean, unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array([np.mean(lines[:,i]) for i in range(len(lines[1,:])-1)])\n",
    "stds = np.array([np.std(lines[:,i]) for i in range(len(lines[1,:])-1)])\n",
    "\n",
    "x_normed = (lines[:,:-1] - lines[:,:-1].mean(axis=0)) / lines[:,:-1].std(axis=0)\n",
    "x_normedt = (linest[:,:-1] - means) / stds\n",
    "y_train = lines[:,-1]\n",
    "y_test = linest[:,-1]\n",
    "#np.savetxt('normed.txt', normed)\n",
    "#np.savetxt('normedt.txt', normedt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function, for FP, FN, TP, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1.0:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1.0 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0.0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0.0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter grid search with 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "# Tuning hyper-parameters for accuracy\nTP: 74, FP: 13, TN: 9, FN: 1\n              precision    recall  f1-score   support\n\n         0.0       0.90      0.41      0.56        22\n         1.0       0.85      0.99      0.91        75\n\n    accuracy                           0.86        97\n   macro avg       0.88      0.70      0.74        97\nweighted avg       0.86      0.86      0.83        97\n\n# Tuning hyper-parameters for precision\nTP: 74, FP: 13, TN: 9, FN: 1\n              precision    recall  f1-score   support\n\n         0.0       0.90      0.41      0.56        22\n         1.0       0.85      0.99      0.91        75\n\n    accuracy                           0.86        97\n   macro avg       0.88      0.70      0.74        97\nweighted avg       0.86      0.86      0.83        97\n\n# Tuning hyper-parameters for recall\nTP: 75, FP: 22, TN: 0, FN: 0\n              precision    recall  f1-score   support\n\n         0.0       0.00      0.00      0.00        22\n         1.0       0.77      1.00      0.87        75\n\n    accuracy                           0.77        97\n   macro avg       0.39      0.50      0.44        97\nweighted avg       0.60      0.77      0.67        97\n\n"
    }
   ],
   "source": [
    "scores = ['accuracy', 'precision', 'recall']\n",
    "best_parameters = {}\n",
    "predictions = {}\n",
    "for score in scores:\n",
    "    print(f\"# Tuning hyper-parameters for {score}\")\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), param_grid, scoring=score, cv=5\n",
    "    )\n",
    "    clf.fit(x_normed, y_train)\n",
    "    best_parameters[score] = clf.best_params_\n",
    "    y_true, predictions[score] = y_test, clf.predict(x_normedt)\n",
    "    TP, FP, TN, FN = perf_measure(y_true, predictions[score])\n",
    "    print(f'TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}')\n",
    "    print(classification_report(y_true, predictions[score]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'accuracy': {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n 'precision': {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n 'recall': {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}}"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=100, gamma=0.001, kernel='rbf')\n",
    "clf.fit(x_normed, y_train)\n",
    "p = clf.predict(x_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9081632653061225"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "sum(p == y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595488706040",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}